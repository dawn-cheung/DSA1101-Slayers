misC[i]=misclass/n
}
}
plot(-log(cp,base=10),misC,type='b')
#smth's very wrong here but uhhh yeah concept shld be there LOL
rep(1:10, length.out = 9)
rep(1:10, length.out = 9)
sample(rep(1:10, length.out = 9))
sample(rep(1:100, length.out = 9))
sample(rep(1:100), length.out = 9)
sample(rep(1:4, length.out = 15))
sample(rep(1:4, length.out = 15))
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=3)
source("~/GitHub/DSA1101 Slayers/Finals Working Materials/past year paper working.R", echo=TRUE)
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=3)
pred.knn.prob= knn(standardised.X, standardised.X, data[,1], prob = TRUE)
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
n = length(data[,1])
prob = numeric(length = n) # n is the length of "test.y" used in knn() above
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
aucLM = performance(pred, measure = "auc")
aucLM@y.values[[1]] #AUC value = 0.9361905
plot(rocObjKNN, lwd =2)
abline(a=0, b=1, col ="blue", lty =3)
)
plot(rocObjKNN, lwd =2)
helppain = prediction(data[,1], prob)
prob
n = length(data[,1])
prob = numeric(length = n) # n is the length of "test.y" used in knn() above
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
prob
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
plot(rocObjKNN, lwd =2)
abline(a=0, b=1, col ="blue", lty =3)
aucLM = performance(pred, measure = "auc")
aucLM@y.values[[1]] #AUC value = 0.9361905
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=3)
pred.knn.prob= knn(standardised.X, standardised.X, data[,1], prob = TRUE)
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
n = length(data[,1])
prob = numeric(length = n) # n is the length of "test.y" used in knn() above
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
print(prob)
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
plot(rocObjKNN, lwd =2)
abline(a=0, b=1, col ="blue", lty =3)
aucLM = performance(pred, measure = "auc")
aucLM@y.values[[1]] #AUC value = 0.9361905
winning.prob
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
winning.prob
accuracy = c()
for (i in 2:10){
M4 <- knn(standardised.X, standardised.X, data[,1], k=i)
confusion.matrix = table(data[,1], M4); confusion.matrix
accuracy = append(accuracy, sum(diag(confusion.matrix))/sum(confusion.matrix))
print(accuracy)
}
accuracy
#best is k = 3
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=2)
pred.knn.prob= knn(standardised.X, standardised.X, data[,1], k=2, prob = TRUE)
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
n = length(data[,1])
prob = numeric(length = n) # n is the length of "test.y" used in knn() above
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
print(prob)
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
plot(rocObjKNN, lwd =2)
abline(a=0, b=1, col ="blue", lty =3)
aucLM = performance(pred, measure = "auc")
aucLM@y.values[[1]] #AUC value = 0.9361905
winning.prob
score = predict(M2, newdata = data[,2:5], type = "response")
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
score
z = c(0, 5, 10)  # 3 points
z2 = z^2 + z*2+ 10
plot(z2~z, type = "l")   #Figure 1
x = seq(0,10, 0.5)
x2 = x^2 + x*2+ 10
plot(x2~x, type = "l") # Figure 2
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
print(prob)
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
plot(0:1, rocObjKNN, lwd =2)
rocObjKNN
M3 <- naiveBayes(Status ~ Life_expectancy + Adult_mortality + infant_deaths + Alcohol,
data)
results <- predict(M3, data[,2:5], "class"); results
confusion.matrix = table(Status, results)
confusion.matrix
diag(confusion.matrix)
accuracy = sum(diag(confusion.matrix))/sum(confusion.matrix)
accuracy
results <- predict(M3, help, type = "raw"); results
# probability: 0.9845948
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red")
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
perf
plot(perf , col = "red", lwd =2)
nbmodel = naiveBayes(diabetes ~ ., train.all)
source("~/GitHub/DSA1101 Slayers/Statistical Report Materials (Assignment 2)/Statistical Report.R", echo=TRUE)
perf
fit <- rpart(diabetes ~ gender + age + hypertension + heart_disease + bmi + HbA1c_level + blood_glucose_level + smoking_history,
method = "class",
data = train.all,
control = rpart.control(cp = 0.001),
parms = list(split = "information"))
rpart.plot(fit, type =4, extra =2, clip.right.labs =FALSE , varlen =0, faclen =0)
preddy = predict(fit, newdata = test.X, type = "class")
perf
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
perf
plot(perf, lwd =2)
naiveB = predict(nbmodel, newdata = test.X, type = "raw") #for NB u need to specify what response variables (from the database) are needed
score = naiveB[, 2]
preObjNB = prediction(score, test.Y)
rocObjNB = performance(preObjNB, measure = "tpr", x.measure = "fpr")
plot(rocObjNB, lwd =2)
nbmodel = naiveBayes(diabetes ~ ., train.all)
results <- predict(nbmodel,test.X,"class"); results
confusion.matrix = table(test.Y, results)
confusion.matrix
diag(confusion.matrix)
accuracy = sum(diag(confusion.matrix))/sum(confusion.matrix)
accuracy
#ROC / AUC for navive bayes
naiveB = predict(nbmodel, newdata = test.X, type = "raw") #for NB u need to specify what response variables (from the database) are needed
score = naiveB[, 2]
preObjNB = prediction(score, test.Y)
rocObjNB = performance(preObjNB, measure = "tpr", x.measure = "fpr")
plot(rocObjNB, lwd =2)
abline(a=0, b=1, col ="blue", lty =3)
plot(rocObjNB, add = TRUE, col = "red") #so to add on to our prev graph
#getting AUC value for NB
aucNB = performance(preObjNB, measure = "auc")
aucNB@y.values[[1]]
helppain = prediction(prob, data[,1])
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=2)
source("~/GitHub/DSA1101 Slayers/Finals Working Materials/past year paper working.R", echo=TRUE)
score = predict(M2, newdata = data[,2:5], type = "response")
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucGLM = performance(pred, measure = "auc")
aucGLM@y.values[[1]]
plot(perf , col = "red", type = "l")
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
perf
fit <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
rpart.plot(fit, type = 4, extra = 2, clip.right.labs = FALSE)
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], "raw")
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")
M4
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
M4
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")
#DECSION TREE
scoreDT
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
#DECSION TREE
scoreDT
predDT <- prediction(score , data[,1])
perfDT <- performance(pred , "tpr", "fpr")
aucDT = performance(pred, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
plot(perfDT , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value:
#Q14
pred.knn =  knn(standardised.X, standardised.X, data[,1], k=2)
pred.knn.prob= knn(standardised.X, standardised.X, data[,1], k=2, prob = TRUE)
winning.prob = attr(pred.knn.prob, "prob") # to extract the winning probabilities
n = length(data[,1])
prob = numeric(length = n) # n is the length of "test.y" used in knn() above
for (i in 1:n) {
prob[i] = ifelse(pred.knn[i] == "yes", winning.prob[i], 1 - winning.prob[i])
print(prob)
}
helppain = prediction(prob, data[,1])
rocObjKNN = performance(helppain, measure = "tpr", x.measure = "fpr")
plot(rocObjKNN, lwd =2, type = "l")
abline(a=0, b=1, col ="blue", lty =3)
aucLM = performance(pred, measure = "auc")
aucLM@y.values[[1]] #AUC value = 0.9361905
z = c(0, 5, 10)  # 3 points
z2 = z^2 + z*2+ 10
plot(z2~z, type = "l")   #Figure 1
x = seq(0,10, 0.5)
x2 = x^2 + x*2+ 10
plot(x2~x, type = "l") # Figure 2
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
rpart.plot(M4, type = 4, extra = 2, clip.right.labs = FALSE)
#most important: Alchohol consumption and life expectancy
results <- predict(M3, help, type = "raw"); results
# probability: 0.9845948
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
predDT <- prediction(score , data[,1])
perfDT <- performance(pred , "tpr", "fpr")
aucDT = performance(pred, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
plot(perfDT , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value:
plot(perfDT, add = TRUE, col = "red", lwd =2)
legend("bottomright", c("Naive Bayes", "Decsion Tree"), col = c("red", "blue"), lty = 1)
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
rpart.plot(M4, type = 4, extra = 2, clip.right.labs = FALSE)
#most important: Alchohol consumption and life expectancy
results <- predict(M3, help, type = "raw"); results
# probability: 0.9845948
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
predDT <- prediction(score , data[,1])
perfDT <- performance(pred , "tpr", "fpr")
aucDT = performance(pred, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9361905
plot(perfDT, add = TRUE, col = "blue", lwd =2)
legend("bottomright", c("Naive Bayes", "Decsion Tree"), col = c("red", "blue"), lty = 1)
plot(perf , col = "red", lwd =2)
plot(perfDT, add = TRUE, col = "blue", lwd =2)
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
predDT <- prediction(score , data[,1])
perfDT <- performance(predDT, "tpr", "fpr")
aucDT = performance(predDT, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
plot(perfDT, add = TRUE, col = "blue", lwd =2)
legend("bottomright", c("Naive Bayes", "Decsion Tree"), col = c("red", "blue"), lty = 1)
x = seq(0,10, 0.5)
x2 = x^2 + x*2+ 10
plot(x2~x, type = "l") # Figure 2
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
rpart.plot(M4, type = 4, extra = 2, clip.right.labs = FALSE)
#most important: Alchohol consumption and life expectancy
results <- predict(M3, help, type = "raw"); results
# probability: 0.9845948
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
predDT <- prediction(score , data[,1])
perfDT <- performance(predDT, "tpr", "fpr")
aucDT = performance(predDT, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
plot(perfDT, add = TRUE, col = "blue", lwd =2)
legend("bottomright", c("Naive Bayes", "Decsion Tree"), col = c("red", "blue"), lty = 1)
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
rpart.plot(M4, type = 4, extra = 2, clip.right.labs = FALSE)
#most important: Alchohol consumption and life expectancy
results <- predict(M3, help, type = "raw"); results
# probability: 0.9845948
score <- predict(M3, data[,2:5], "raw")[,2]
pred <- prediction(score , data[,1])
perf <- performance(pred , "tpr", "fpr")
aucNB = performance(pred, measure = "auc")
aucNB@y.values[[1]] #auc value = 0.9361905
plot(perf , col = "red", lwd =2)
abline(a=0, b=1, col ="blue", lty =3)#AUC value: 0.9342857
#DECSION TREE
scoreDT <- predict(M4, data[,2:5], type = "prob")[,2]
predDT <- prediction(scoreDT, data[,1])
perfDT <- performance(predDT, "tpr", "fpr")
aucDT = performance(predDT, measure = "auc")
aucDT@y.values[[1]] #auc value = 0.9361905
plot(perfDT, add = TRUE, col = "blue", lwd =2)
legend("bottomright", c("Naive Bayes", "Decsion Tree"), col = c("red", "blue"), lty = 1)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
data = read.csv("~/Github/DSA1101 Slayers/datasets/Titanic.csv")
glimpse(data)
#data$Survived = as.factor(data$Survived)
#data$Sex = as.factor(data$Sex)
#data$Class = as.factor(data$Class)
attach(data)
prop.table(table(Survived))
ProbY1 = prop.table(table(Survived))[[1]] #double bracket to remove the column name
ProbY0 = prop.table(table(Survived))[[2]]
ProbY1
ProbY0
#> tprior <- table(Survived) # Number of ppl survived & not survived
#> tprior
#Survived
#  No  Yes
#1490  711
#> tprior <- tprior/sum(tprior) # the probability scores
#> tprior
#Survived
#      No      Yes
#0.676965 0.323035
#P(Xi = xi |Y = 1) = P(class = 3rd)
c = table(Survived, Class); c
s = table(Survived, Sex); s
a = table(Survived, Age); a
c = c/rowSums(c); c #remember that u shld divide by the total number of yes/no OF THE WHOLE DATASET
s = c/rowSums(s); s
a = c/rowSums(a); a
#to add all rows: rowSums()
#        Class
#Survived        1st        2nd        3rd       Crew
#     No  0.08187919 0.11208054 0.35436242 0.45167785
#     Yes 0.28551336 0.16596343 0.25035162 0.29817159
#NOTE: completely wrong to use prop.table. we need to get the total divisible to be the entire dataset(?)
#P(Y = survive |Age = Adult, Sex = Female, Class = 2nd)
Yum = ProbY1 * c[[2,2]] * s[[1,2]] * s[[1,2]]
NotYum = ProbY0 * c[[2,1]] * s[[1,1]] * s[[1,1]]
if (Yum > NotYum) {
print("more likely to survive")
} else {
print("death is inevitable")
}
library("e1071")
M1 <- naiveBayes(Survived ~ Age + Sex + Class, data)#, laplace=0)
newdata = cbind(Age = "Adult", Sex = "Female", Class = "2nd") #maybe use data.frame() instead
predict(M1, newdata = newdata, type = "class")
predict(M1, newdata = newdata, type = "raw")
#prediction is the sameeeee
rpart.plot(M2, type = 4, extra = 2, clip.right.labs = FALSE)
library(rpart)
library(rpart.plot)
M2 <- rpart(Survived ~ Age + Sex + Class,
method = "class",
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
summary(M2)
rpart.plot(M2, type = 4, extra = 2, clip.right.labs = FALSE)
library(dplyr)
library(ROCR)
ncol(data)
sur = ifelse(Survived == "Yes", 1,0)
sur = as.factor()
library(dplyr)
library(ROCR)
ncol(data)
sur = ifelse(Survived == "Yes", 1,0)
data
# > typeof(data.frame(data[,-ncol(data)]))
# [1] "list"
#HUHHHH
#do NB first
nb_prediction = predict(M1,
newdata = data.frame(data[,-ncol(data)]),
type = "raw")
dt_prediction = predict(M2, newdata = data.frame(data[,-ncol(data)]), type = "raw")
library(dplyr)
library(ROCR)
ncol(data)
sur = ifelse(Survived == "Yes", 1,0)
data
# > typeof(data.frame(data[,-ncol(data)]))
# [1] "list"
#HUHHHH
#do NB first
nb_prediction = predict(M1,
newdata = data.frame(data[,-ncol(data)]),
type = "raw")
dt_prediction = predict(M2, newdata = data.frame(data[,-ncol(data)]), type = "prob")
nb_predicted_score = nb_prediction[,c("Yes")]
dt_predicted_score = dt_prediction[,c("Yes")]
actual_class = data$Survived == "Yes"
nb_pred = prediction(nb_predicted_score, actual_class)
dt_pred = prediction(dt_predicted_score, actual_class)
nb_perf <- performance(nb_pred , "tpr", "fpr")
dt_perf <- performance(dt_pred , "tpr", "fpr")
auc1 <- performance(pre_nb, "auc")@y.values[[1]]
library(dplyr)
library(ROCR)
ncol(data)
sur = ifelse(Survived == "Yes", 1,0)
data
# > typeof(data.frame(data[,-ncol(data)]))
# [1] "list"
#HUHHHH
#do NB first
nb_prediction = predict(M1,
newdata = data.frame(data[,-ncol(data)]),
type = "raw")
dt_prediction = predict(M2, newdata = data.frame(data[,-ncol(data)]), type = "prob")
nb_predicted_score = nb_prediction[,c("Yes")]
dt_predicted_score = dt_prediction[,c("Yes")]
actual_class = data$Survived == "Yes"
nb_pred = prediction(nb_predicted_score, actual_class)
dt_pred = prediction(dt_predicted_score, actual_class)
nb_perf <- performance(nb_pred , "tpr", "fpr")
dt_perf <- performance(dt_pred , "tpr", "fpr")
auc1 <- performance(nb_pred, "auc")@y.values[[1]]
#REMEMBER MUST CONVERT TO 0 and 1
sur = (Survived == "Yes")
sur = as.factor(sur)
data$sur = sur #so sur is a completely new column to mutate onto the database
attach(data)
glimpse(data)
#note that glm is an in-built function-- no library needed
M3 <- glm(sur ~ Age + Sex + Class,
data = data,
family = binomial(link = "logit")) #family decides the transformation g from g(y)
summary(M3)
library(ROCR)
#ROC for Log Reg
pred = predict(M3, type = "response")
preObj = prediction(pred, data$Survived) #notice here we don't need to use sur, the OG column is fine
rocObj = performance(preObj, measure = "tpr", x.measure = "fpr")
plot(rocObj)
#getting AUC value for Log Reg
aucLR = performance(preObj, measure = "auc")
aucLR@y.values[[1]] #0.7597259
#ROC for NB
#Naive Bayes requires more formatting!!!
naiveB = predict(M1, data[1:3], type = "raw") #for NB u need to specify what response variables (from the database) are needed
score = naiveB[, 2]
#OK SO naiveB[,c("Yes")] and naiveB[,2] IS THE SAME bc u see what predict() returns
#                No       Yes
#   [1,] 0.69605930 0.3039407
#   [2,] 0.69605930 0.3039407
#   [3,] 0.69605930 0.3039407
#yea so basically u want that Yes column
#these are the predicted Yes'es by the way
preObjNB = prediction(score, data$sur)
rocObjNB = performance(preObjNB, measure = "tpr", x.measure = "fpr")
plot(rocObjNB, add = TRUE, col = "red") #so to add on to our prev graph
#getting AUC value for NB
aucNB = performance(preObjNB, measure = "auc")
aucNB@y.values[[1]]
legend("bottomright", c("Logistic Regression", "Naive Bayes"), col = c("black", "red"), lty = 1)
preObjNB
rocObjNB
score <- predict(M3, data[,2:5], "raw")[,2]
M4 <- rpart(Status ~ .,
method = "class",
data = data,
control = rpart.control(cp = 0.001),
parms = list(split = "gini"))
source("~/GitHub/DSA1101 Slayers/Finals Working Materials/past year paper working.R", echo=TRUE)
