knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
}
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = c(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[-i], ]
test.X = stand.X[COMBINE[i], ]
train.Y = data[COMBINE[-i], 1]
test.Y = data[COMBINE[i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = c(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[-i], ]
test.X = stand.X[COMBINE[i], ]
train.Y = data[COMBINE[-i], 1]
test.Y = data[COMBINE[i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
killme
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
COMBINE[-3]
COMBINE[3]
COMBINE[[3]]
COMBINE = c(A = setA, B = setB, C = setC, D = setD, E = setE)
COMBINE[-3]
COMBINE
COMBINE = data.frame(A = setA, B = setB, C = setC, D = setD, E = setE)
PLEASE = c(A, B, C, D, E)
COMBINE = data.frame(A = setA, B = setB, C = setC, D = setD, E = setE)
PLEASE = c(A, B, C, D, E)
COMBINE = data.frame(setA, setB, setC, setD, setE)
train.X = stand.X[COMBINE[-i], ]
train.X = stand.X[COMBINE[,-i], ]
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[,-i], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
for (i in 1:5) {
train.X = stand.X[COMBINE[,i], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
for (i in 1:5) {
train.X = stand.X[COMBINE[[,-i]], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
COMBINE[,1]
COMBINE[,-1]
test.X = stand.X[COMBINE[i], ]
test.X = stand.X[unlist(COMBINE[i]), ]
COMBINE[-1]
COMBINE[-1,]
-COMBINE[1,]
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
-COMBINE[1,]
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[-i]), ]
test.X = stand.X[unlist(COMBINE[i]), ]
train.Y = data[unlist(COMBINE[-i]), 1]
test.Y = data[unlist(COMBINE[i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
-COMBINE[1,]
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[,-i]), ]
test.X = stand.X[unlist(COMBINE[,i]), ]
train.Y = data[unlist(COMBINE[,-i]), 1]
test.Y = data[unlist(COMBINE[,i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
please <- function(HELPME = 1) {
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[,-i]), ]
test.X = stand.X[unlist(COMBINE[,i]), ]
train.Y = data[unlist(COMBINE[,-i]), 1]
test.Y = data[unlist(COMBINE[,i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = HELPME)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
#i want to mf kms
}
please()
please()
for (i in 1:100) {
please(i)
}
please()
for (i in 1:100) {
please(i)
}
please()
for (i in 1:100) {
please(i) #HKJDVLkhcy: whyw yfirvlhkea:
}
knitr::opts_chunk$set(echo = TRUE)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv")
head(iris)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
head(iris)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
head(iris)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(class)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv") #Q1
attach(data)
glimpse(data)
stand.X = scale(data[,2:5])
#jbfhdkjsvlkdjh
#end me
sample <- read.table("~/Github/DSA1101 Slayers/datasets/sample1.csv",header=TRUE,sep=",")
head(sample)
dim(sample)
sample
attach(sample)
glimpse(sample)
library(tidyverse)
glimpse(sample)
# get the probability of each categories of the response
tprior <- table(traindata$Enrolls);tprior
traindata <- as.data.frame(sample[1:14,])
testdata <- as.data.frame(sample[15,])
testdata
# get the probability of each categories of the response
tprior <- table(traindata$Enrolls);tprior
tprior <- tprior/sum(tprior); tprior
ageCounts <- table(traindata[,c("Enrolls", "Age")]);ageCounts
ageCounts <- ageCounts/rowSums(ageCounts); ageCounts
# Get P(X = xi|Y = yj): row-wise proportion for feature INCOME
incomeCounts <- table(traindata[,c("Enrolls", "Income")])
incomeCounts <- incomeCounts/rowSums(incomeCounts);incomeCounts
# Get P(X = xi|Y = yj): row-wise proportion for feature JOBSATISFACTION
jsCounts <- table(traindata[,c("Enrolls", "JobSatisfaction")])
jsCounts <- jsCounts/rowSums(jsCounts);jsCounts
# Get P(X = xi|Y = yj): row-wise proportion for feature DESIRE
desireCounts <- table(traindata[,c("Enrolls", "Desire")])
desireCounts <- desireCounts/rowSums(desireCounts);desireCounts
prob_yes <-
ageCounts["Yes",testdata[,c("Age")]]*
incomeCounts["Yes",testdata[,c("Income")]]*
jsCounts["Yes",testdata[,c("JobSatisfaction")]]*
desireCounts["Yes",testdata[,c("Desire")]]*
tprior["Yes"]
prob_yes
library(e1071)
model <- naiveBayes(Enrolls ~ Age+Income+JobSatisfaction+Desire, traindata)#, laplace=0)
#model <- naiveBayes(response_var ~ predictor1 + predictor2, traindata)
results <- predict(model,testdata,"raw"); results
results[2]/results[1] # 4.115226
results <- predict(model,testdata,"class"); results
library(ROCR)
banktrain <- read.csv("~/Github/DSA1101 Slayers/datasets/bank-sample.csv", header=TRUE)
dim(banktrain)
head(banktrain)
# drop a few UNNECESSARY columns for the TRANNING DATA SET
drops <- c("balance", "day", "campaign", "pdays", "previous", "month")
banktrain <- banktrain [,!(names(banktrain) %in% drops )]
# TESTING DATA SET
banktest <- read.csv("C:/Data/bank-sample-test.csv")
banktrain <- read.csv("~/Github/DSA1101 Slayers/datasets/bank-sample.csv", header=TRUE)
dim(banktrain)
head(banktrain)
# drop a few UNNECESSARY columns for the TRANNING DATA SET
drops <- c("balance", "day", "campaign", "pdays", "previous", "month")
banktrain <- banktrain [,!(names(banktrain) %in% drops )]
# TESTING DATA SET
banktest <- read.csv("~/Github/DSA1101 Slayers/datasets/bank-sample-test.csv")
banktest <- banktest[,!( names ( banktest ) %in% drops )]
library(e1071)
# build the naive Bayes classifier
nb_model <- naiveBayes( subscribed ~., data = banktrain)
# perform on the test set BUT we need to remove the respponse column first
head(banktest);
ncol(banktest) # number of columns = 11. Respone = 11th column.
nb_prediction <- predict(nb_model, newdata = banktest[,-ncol(banktest)], type ='raw') #remove the last column bc thats the response variable: u cant use the response variable to determine the response variable lol
# this is the predicted response for the test set
nb_prediction
cbind(nb_prediction, banktest[,ncol(banktest)])
library(ROCR)
score <- nb_prediction[, c("yes")]
actual_class <- banktest$subscribed == 'yes' # actual response is 0 or 1
pred <- prediction(score , actual_class)
pred <- prediction(score , actual_class)
# this is to "format" the input so that we can use the function in ROCR to get TPR and FPR
perf <- performance(pred , "tpr", "fpr")
plot (perf, lwd =2) # lwd is to specify how thick the curve is
plot (perf, lwd =2) # lwd is to specify how thick the curve is
abline (a=0, b=1, col ="blue", lty =3)
auc <- performance(pred , "auc")@y.values[[1]]
#auc <- unlist(slot (auc , "y.values"))
auc
# auc is used to compare between Naive Bayes methd with other
# methods such as linear model, logistic model, DT, etc.
# the one with larger auc value is better.
setwd("~/GitHub/DSA1101 Slayers")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
glimpse(data)
data$Churned = as.factor(data$Churned)
glimpse(data)
attach(data)
data$Churned = as.factor(data$Churned)
data$Married = as.factor(data$Married)
glimpse(data)
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
glimpse(data)
data$Churned = as.factor(data$Churned)
data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = class,
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = class,
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
#data$Churned = as.factor(data$Churned)
#data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = class,
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
data$Churned = as.factor(data$Churned)
data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = "class",
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
rpart.plot(fit, type = 4, extra = 2, clip.right.labs = FALSE)
library(tidyverse)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
data$Churned = as.factor(data$Churned)
data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = "class",
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
rpart.plot(fit, type = 4, extra = 2, clip.right.labs = FALSE)
WHY = data.frame(Age = c(26, 23,56,36,45,28,22,22,60,32),
Married = as.factor(c(1,1,1,1,0,0,1,0,1,0)),
Cust_years = c(2,3,5,5,2,2,3,3,2,3),
Churned_contacts = c(2,3,2,2,1,2,0,2,1,1))
predict(fit, newdata = WHY, type = "class")
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
len = iris[which(class == "Iris-setosa")]
len = iris[,which(class == "Iris-setosa")]
len = iris[ ,which(class == "Iris-setosa")]
len = iris[4,which(class == "Iris-setosa")]
which(class == "Iris-setosa")
len = iris[which(class == "Iris-setosa"),]
len
knitr::opts_chunk$set(echo = TRUE)
setA = sample(1:100)
setosa = sample(iris[which(class == "Iris-setosa"),])
setosa = iris[which(class == "Iris-setosa"),]
library(tidyverse)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/churn.csv")
data$Churned = as.factor(data$Churned)
data$Married = as.factor(data$Married)
glimpse(data)
attach(data)
fit <- rpart(Churned ~ Age + Married + Cust_years + Churned_contacts,
method = "class",
data = data,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
rpart.plot(fit, type = 4, extra = 2, clip.right.labs = FALSE)
WHY = data.frame(Age = c(26, 23,56,36,45,28,22,22,60,32),
Married = as.factor(c(1,1,1,1,0,0,1,0,1,0)),
Cust_years = c(2,3,5,5,2,2,3,3,2,3),
Churned_contacts = c(2,3,2,2,1,2,0,2,1,1))
predict(fit, newdata = WHY, type = "class")
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
setosa = iris[which(class == "Iris-setosa"),]
virginica = iris[which(class == "Iris-virginica"),]
versicolor = iris[which(class == "Iris-versicolor"),]
setA = sample(1:100)
setosa = sample(iris[which(class == "Iris-setosa"),])
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
setosa = sample(iris[which(class == "Iris-setosa"),])
virginica = sample(iris[which(class == "Iris-virginica"),])
versicolor = sample(iris[which(class == "Iris-versicolor"),])
helpp = c()
for (q in 1:5) {
for (i in 1:10) {
w = ((q-1) * 10) + i
place = rbind(sentosa[w], virginica[w], versicolor[w])
}
helpp = c(place, helpp)
}
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
setosa = sample(iris[which(class == "Iris-setosa"),])
virginica = sample(iris[which(class == "Iris-virginica"),])
versicolor = sample(iris[which(class == "Iris-versicolor"),])
helpp = c()
for (q in 1:5) {
for (i in 1:10) {
w = ((q-1) * 10) + i
place = rbind(setosa[w], virginica[w], versicolor[w])
}
helpp = c(place, helpp)
}
View(virginica)
for (q in 1:5) {
for (i in 1:10) {
w = ((q-1) * 10) + i
place = rbind(setosa[w,], virginica[w,], versicolor[w,])
}
helpp = c(place, helpp)
}
View(helpp)
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
setosa = sample(iris[which(class == "Iris-setosa"),])
virginica = sample(iris[which(class == "Iris-virginica"),])
versicolor = sample(iris[which(class == "Iris-versicolor"),])
helpp = c()
place = c()
for (q in 1:5) {
for (i in 1:10) {
w = ((q-1) * 10) + i
place = rbind(place, setosa[w,], virginica[w,], versicolor[w,])
}
helpp = c(place, helpp)
}
