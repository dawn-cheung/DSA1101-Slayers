train.x = breastdata[c(setA, setB), c(1,2)]
test.x = breastdata[setC, c(1,2)]
train.y = breastdata[c(setA, setB), c(1,2)]
knn.pred = knn(train.x, test.x, train.y, k = 3)
train.x = breastdata[c(setA, setB), c(1,2)]
test.x = breastdata[setC, c(1,2)]
train.y = breastdata[c(setA, setB), c(3)]
knn.pred = knn(train.x, test.x, train.y, k = 3)
table(knn.pred)
predict(knn.pred, test.y)
predict(knn.pred, test.y, type = "class")
data.frame(test.y, knn.pred)
breastdata$survival.status = as.factor(breastdata$survival.status)
breastdata = breastdata[,c(1,3,4)]
library(class)
breastdata = read.csv("~/Github/DSA1101 Slayers/datasets/data2.csv")
breastdata$survival.status = as.factor(breastdata$survival.status)
breastdata = breastdata[,c(1,3,4)]
attach(breastdata)
glimpse(breastdata)
set.seed(999)
setA = sample(1:306, size = 102)
q = 1:306
q = q[which(q != setA)]
setB = sample(q, size = 102)
q = q[which(q != setB)]
setC = sample(q, size = 102)
train.x = breastdata[c(setA, setB), c(1,2)]
test.x = breastdata[setC, c(1,2)]
train.y = breastdata[c(setA, setB), c(3)]
test.y = breastdata[setC, c(3)]
knn.pred = knn(train.x, test.x, train.y, k = 3)
data.frame(test.y, knn.pred)
table(result)
result = data.frame(test.y, knn.pred)
table(result)
FPR = result[2,1] / (result[2,1] + result[2,2])
FNR = result[1,2] / (result[1,1] + result[1,2])
library(class)
breastdata = read.csv("~/Github/DSA1101 Slayers/datasets/data2.csv")
breastdata$survival.status = as.factor(breastdata$survival.status)
breastdata = breastdata[,c(1,3,4)]
attach(breastdata)
glimpse(breastdata)
set.seed(999)
setA = sample(1:306, size = 102)
q = 1:306
q = q[which(q != setA)]
setB = sample(q, size = 102)
q = q[which(q != setB)]
setC = sample(q, size = 102)
train.x = breastdata[c(setA, setB), c(1,2)]
test.x = breastdata[setC, c(1,2)]
train.y = breastdata[c(setA, setB), c(3)]
test.y = breastdata[setC, c(3)]
knn.pred = knn(train.x, test.x, train.y, k = 3)
result = data.frame(test.y, knn.pred)
result = table(result)
FPR = result[2,1] / (result[2,1] + result[2,2])
FNR = result[1,2] / (result[1,1] + result[1,2])
####MIDTERM ANSWERS
library(tidyverse)
library(dplyr)
library(class)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/abalone2.csv") #Q1
set.seed(803)
glimpse(data)
data$sex = as.factor(data$sex)
attach(data)
#2
head(data)
#rownames(data)
#report of names of all the columns: sex, length, diameter, weight,  age
#3
Year = age
Year[which(age <= 10.5)] = "young"
Year[which(age > 10.5)] = "old"
#data %>%
#  mutate(Year = Year)
#Q4
table(Year)
#Q5
qqnorm(age, pch = 10)
qqline(age, col = "red")
#comments: the distribution of age is not normal because from theoretical quantiles 1 and above, the QQ plot curves upwards away from the red line.
#hence the left tail is shorter than normal
#However, when theoretical quantiles is between -2 and 1, the plots are on the red line, so in the range it can be considered normal
#Q6
boxplot(age, xlab = "variable", col = "blue")
Outlier = boxplot(age)$out
length(Outlier)
#there are 278 outliers
# There are multiple outliers, 3 are below the median and the rest above.
#Q7
#assume that 'large outliers' are outliers detected by R
out_weight = weight[which(age == Outlier)]
mean(out_weight)
mean(weight)
#the mean of the outlier weights is larger by the
#mean of the weights in the entire dataset
mean(out_weight) - mean(weight)
#the difference is 53.53811
#which is relatively large
#Q8
plot(age, weight)
#general positive relationship
#as age increases, variability of weight increases significantly
#not good for linear model
###PART III
#Q9
M1 = lm(age ~ sex + length + diameter + weight)
#factor done earleir
summary (M1)
#I(sex = "M") and weight are not significant
#p-values:
#I(sex = "M"): 0.0679
#weight: 0.1049
#10
plot(M1)
Q = data.frame(sex = "M", length = 120, diameter = 90, weight = 240)
predict(M1, Q, type = "class")
Q = data.frame(sex = "M", length = 120, diameter = 90, weight = 240)
predict(M1, Q)
#using length, diameter, weight
glimpse(data)
stand.X = scale(data[, 2:4])
stand.X
test.x =
train.y =
4177/5
4177/5
4177-835
stand.X = scale(data[, 2:4])
type2 = c()
#using length, diameter, weight
glimpse(data)
stand.X = scale(data[, 2:4])
setA = sample(1:4177, size = 835)
q = 1:4177
q = q[which(q != setA)]
setB = sample(q, size = 3342)
train.x = stand.X[setB,]
test.x = stand.X[setA,]
train.y = Year[setB]
#test.y = data[setC, c(3)]
knn.pred = knn(train.x, test.x, train.y, k = 1)
result = data.frame(test.y, knn.pred)
type2 = c()
#using length, diameter, weight
glimpse(data)
stand.X = scale(data[, 2:4])
setA = sample(1:4177, size = 835)
q = 1:4177
q = q[which(q != setA)]
setB = sample(q, size = 3342)
train.x = stand.X[setB,]
test.x = stand.X[setA,]
train.y = Year[setB]
test.y = Year[setA]
knn.pred = knn(train.x, test.x, train.y, k = 1)
result = data.frame(test.y, knn.pred)
result = table(result)
T1 = result[2,1] / (result[2,1] + result[2,2])
T2 = result[1,2] / (result[1,1] + result[1,2])
T1
T2
type2 = c()
#using length, diameter, weight
glimpse(data)
stand.X = scale(data[, 2:4])
setA = sample(1:4177, size = 835)
q = 1:4177
q = q[which(q != setA)]
setB = sample(q, size = 3342)
for (i in 11:50) {
train.x = stand.X[setB,]
test.x = stand.X[setA,]
train.y = Year[setB]
test.y = Year[setA]
knn.pred = knn(train.x, test.x, train.y, k = i)
result = data.frame(test.y, knn.pred)
result = table(result)
T1 = result[2,1] / (result[2,1] + result[2,2])
T2 = result[1,2] / (result[1,1] + result[1,2])
type2 = c(type2, T2)
}
plot(type2, 11:50)
plot(11:50, type2)
W = data.frame(no = 11:50, type2 = type2)
W[which(no = 46)]
W = data.frame(no = 11:50, type2 = type2)
W[which(no = 46), 2]
W
W = data.frame(no = 11:50, type2 = type2)
W[which(no == 46), 2]
W[which(W$no == 46), 2]
W[which(W$no == 45), 2]
#response variable: subscribed (yes/no)
#we have 16 features => not using all (we will use 8)
fit <- rpart(Year ~ length + diameter + weight,
method = "class",
data = bankdata,
control = rpart.control(cp = 0.003),
parms = list(split = "information"))
#response variable: subscribed (yes/no)
#we have 16 features => not using all (we will use 8)
fit <- rpart(Year ~ length + diameter + weight,
method = "class",
data = data,
control = rpart.control(cp = 0.003),
parms = list(split = "information"))
rpart.plot(fit, type = 4, extra = 2, clip.right.labs = FALSE)
#17
table(fit)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(class)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv") #Q1
glimpse(data)
library(tidyverse)
library(dplyr)
library(class)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv") #Q1
attach(data)
glimpse(data)
stand.X = scale(data[,2:5])
#jbfhdkjsvlkdjh
#end me
setA = sample(1:1000, size = 800)
q = 1:4177
q = q[which(q != setA)]
setB = sample(q, size = 3342)
train.X = stand.X[setA, ]
test.X = stand.X[setB, ]
setA = sample(1:1000, size = 800)
q = 1:1000
q = q[which(q != setA)]
setB = sample(q, size = 200)
train.X = stand.X[setA, ]
test.X = stand.X[setB, ]
train.Y = data[setA, 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
table(knn.pred, test.Y)
setA = sample(1:1000, size = 800)
q = 1:1000
q = q[which(q != setA)]
setB = sample(q, size = 200)
train.X = stand.X[setA, ]
test.X = stand.X[setB, ]
train.Y = data[setA, 1]
test.Y = data[setB, 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
table(knn.pred, test.Y)
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 1000
acc
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
acc
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = c(setA, setB, setC, setD, setE)
for (i in 1:5) {
train.X = stand.X[setA, ]
test.X = stand.X[setB, ]
train.Y = data[setA, 1]
test.Y = data[setB, 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
}
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = c(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[-i], ]
test.X = stand.X[COMBINE[i], ]
train.Y = data[COMBINE[-i], 1]
test.Y = data[COMBINE[i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = c(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[-i], ]
test.X = stand.X[COMBINE[i], ]
train.Y = data[COMBINE[-i], 1]
test.Y = data[COMBINE[i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
killme
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
COMBINE[-3]
COMBINE[3]
COMBINE[[3]]
COMBINE = c(A = setA, B = setB, C = setC, D = setD, E = setE)
COMBINE[-3]
COMBINE
COMBINE = data.frame(A = setA, B = setB, C = setC, D = setD, E = setE)
PLEASE = c(A, B, C, D, E)
COMBINE = data.frame(A = setA, B = setB, C = setC, D = setD, E = setE)
PLEASE = c(A, B, C, D, E)
COMBINE = data.frame(setA, setB, setC, setD, setE)
train.X = stand.X[COMBINE[-i], ]
train.X = stand.X[COMBINE[,-i], ]
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[COMBINE[,-i], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
for (i in 1:5) {
train.X = stand.X[COMBINE[,i], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
for (i in 1:5) {
train.X = stand.X[COMBINE[[,-i]], ]
test.X = stand.X[COMBINE[,i], ]
train.Y = data[COMBINE[,-i], 1]
test.Y = data[COMBINE[,i], 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
COMBINE[,1]
COMBINE[,-1]
test.X = stand.X[COMBINE[i], ]
test.X = stand.X[unlist(COMBINE[i]), ]
COMBINE[-1]
COMBINE[-1,]
-COMBINE[1,]
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
-COMBINE[1,]
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[-i]), ]
test.X = stand.X[unlist(COMBINE[i]), ]
train.Y = data[unlist(COMBINE[-i]), 1]
test.Y = data[unlist(COMBINE[i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
aveacc_count = c()
-COMBINE[1,]
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[,-i]), ]
test.X = stand.X[unlist(COMBINE[,i]), ]
train.Y = data[unlist(COMBINE[,-i]), 1]
test.Y = data[unlist(COMBINE[,i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = 1)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
setA = sample(1:1000, size = 200)
q = 1:1000
#i know this can be automated but im too tired for this
q = q[which(q != setA)]
setB = sample(q, size = 200)
q = q[which(q != setB)]
setC = sample(q, size = 200)
q = q[which(q != setC)]
setD = sample(q, size = 200)
q = q[which(q != setC)]
setE = sample(q, size = 200)
COMBINE = data.frame(setA, setB, setC, setD, setE)
please <- function(HELPME = 1) {
aveacc_count = c()
for (i in 1:5) {
train.X = stand.X[unlist(COMBINE[,-i]), ]
test.X = stand.X[unlist(COMBINE[,i]), ]
train.Y = data[unlist(COMBINE[,-i]), 1]
test.Y = data[unlist(COMBINE[,i]), 1]
knn.pred = knn(train.X, test.X, train.Y, k = HELPME)
knn.pred
killme = table(knn.pred, test.Y)
acc = (killme[1,1] + killme[2,2]) / 200
aveacc_count = c(aveacc_count, acc)
}
mean(aveacc_count)
#i want to mf kms
}
please()
please()
for (i in 1:100) {
please(i)
}
please()
for (i in 1:100) {
please(i)
}
please()
for (i in 1:100) {
please(i) #HKJDVLkhcy: whyw yfirvlhkea:
}
knitr::opts_chunk$set(echo = TRUE)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv")
head(iris)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
head(iris)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
head(iris)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(class)
library(rpart)
library(rpart.plot)
data = read.csv("~/Github/DSA1101 Slayers/datasets/German_credit.csv") #Q1
attach(data)
glimpse(data)
stand.X = scale(data[,2:5])
#jbfhdkjsvlkdjh
#end me
