table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, iris$class)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
#OK OG IDEA WAS TOO COMPLICATED LMAO
#better idea: split setosa, virginica and vericolor
# then split each of those 3 grps into 5 groups, randomly
# then add 1 fold from each of the seperated sub-groups
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
confusion.matrix
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
```
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
#OK OG IDEA WAS TOO COMPLICATED LMAO
#better idea: split setosa, virginica and vericolor
# then split each of those 3 grps into 5 groups, randomly
# then add 1 fold from each of the seperated sub-groups
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
n_folds=5 #
folds_j_1 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 1 = setosa
folds_j_2 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 2 = versicolor
folds_j_3 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 2 = virginica
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
data1 = iris[1:50,] # data for type 1 = setosa
data2 = iris[51:100,] # data for type 2 = versicolor
data3 = iris[101:150,] # data for type 3 = virginica
acc=numeric(n_folds)
j= 1
for (j in 1:n_folds) {
test1 <- which(folds_j_1 == j)
test2 <- which(folds_j_2 == j)
test3 <- which(folds_j_3 == j)
train.1=data1[ -test1, ]
train.2=data2[ -test2, ]
train.3=data3[ -test3, ]
train = rbind(train.1, train.2, train.3) # this is the training data set
test = rbind(data1[test1,], data2[test2,], data3[test3,] ) # test data
fit.iris <- rpart(class ~ .,
method = "class", data =train, control = rpart.control( minsplit =1),
parms = list( split ='gini'))
pred = predict(fit.iris, newdata = test[,1:4], type = 'class')
confusion.matrix = table(pred, test[,5])
acc[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)
}
acc
mean(acc) # the accuracy is very high, 0.94
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
j = 1
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
j = 1
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test[1:4], type = 'class')
confusion.matrix = table(pred, real)
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
j = 1
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test[1:4], type = 'class')
confusion.matrix = table(pred, test[,5])
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
confusion.matrix = table(pred, test[,5])
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
j = 1
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test[1:4], type = 'class')
confusion.matrix = table(pred, real)
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
library(tidyverse)
library(rpart)
library(rpart.plot)
iris = read.csv("~/Github/DSA1101 Slayers/datasets/iris.csv")
glimpse(iris)
iris$class = as.factor(iris$class)
attach(iris) #is class supp to be a factor(??)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = iris,
control = rpart.control(minsplit = 1),
parms = list(split = "information"))
#OK OG IDEA WAS TOO COMPLICATED LMAO
#better idea: split setosa, virginica and vericolor
# then split each of those 3 grps into 5 groups, randomly
# then add 1 fold from each of the seperated sub-groups
set.seed(555)
n_folds = 5
#generate the indexes
folds_j_1 = sample(rep(1:n_folds, length.out = 50)) #for type 1 = setosa
folds_j_2 = sample(rep(1:n_folds, length.out = 50))
folds_j_3 = sample(rep(1:n_folds, length.out = 50))
accuracy = numeric(n_folds)
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
#note that the data is alr separated such that the first 50 is setosa, next 50 is virginica, and last 50 is vericolor
#so we can separate them this way
data1 = iris[1:50, ]
data2 = iris[51:100, ]
data3 = iris[101:150, ]
j = 1
for (j in 1:n_folds) {
test1 = which(folds_j_1 == j)
test2 = which(folds_j_2 == j)
test3 = which(folds_j_3 == j)
train.1 = data1[-test1, ] #everything but the test set
train.2 = data2[-test2, ]
train.3 = data3[-test3, ]
train = rbind(train.1, train.2, train.3)
fit <- rpart(class ~ sepal.length + sepal.width + petal.length + petal.width,
method = "class",
data = train,
control = rpart.control(minsplit = 1),
parms = list(split = "gini")) #or information gain, all ok
test = rbind(data1[test1,1:4],
data2[test2,1:4],
data3[test3,1:4])
real = rbind(data1[test1,5],
data2[test2,5],
data3[test3,5]) #real response for the test data
#note u cant use the entire class cus its too many values
pred = predict(fit, newdata = test, type = 'class')
confusion.matrix = table(pred, real)
print(confusion.matrix)
accuracy[j] = sum(diag(confusion.matrix)/sum(confusion.matrix))
}
accuracy
mean(accuracy)
View(iris)
set.seed(555)
n_folds=5 #
folds_j_1 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 1 = setosa
folds_j_2 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 2 = versicolor
folds_j_3 <- sample(rep(1:n_folds, length.out = 50 ))  # for type 2 = virginica
table(folds_j_1)
table(folds_j_2)
table(folds_j_3)
data1 = iris[1:50,] # data for type 1 = setosa
data2 = iris[51:100,] # data for type 2 = versicolor
data3 = iris[101:150,] # data for type 3 = virginica
acc=numeric(n_folds)
j= 1
for (j in 1:n_folds) {
test1 <- which(folds_j_1 == j)
test2 <- which(folds_j_2 == j)
test3 <- which(folds_j_3 == j)
train.1=data1[ -test1, ]
train.2=data2[ -test2, ]
train.3=data3[ -test3, ]
train = rbind(train.1, train.2, train.3) # this is the training data set
test = rbind(data1[test1,], data2[test2,], data3[test3,] ) # test data
fit.iris <- rpart(class ~ .,
method = "class", data =train, control = rpart.control( minsplit =1),
parms = list( split ='information'))
pred = predict(fit.iris, newdata = test[,1:4], type = 'class')
confusion.matrix = table(pred, test[,5])
acc[j] = sum(diag(confusion.matrix))/sum(confusion.matrix)
}
acc
mean(acc) # the accuracy is very high, 0.94
test = c(1, 2, 3,5, 7)
bakntrain = read.csv("bank-sample.csv", header = T)
library(tidyverse)
bakntrain = read.csv("bank-sample.csv", header = T)
banktrain = read.csv("bank-sample.csv", header = T)
banktrain = read.csv("~/Github/DSA1101 Slayers/datasets/bank-sample.csv", header = T)
banktrain = banktrain[,!names(banktrain) %in% drops]
banktrain = read.csv("~/Github/DSA1101 Slayers/datasets/bank-sample.csv", header = T)
drops = c("age", "balance", "day", "campaign", "pdays", "previous", "month", "duration")
banktrain = banktrain[,!names(banktrain) %in% drops]
# returns a list of boonleans
attach(banktrain)
head(banktrain)
source("~/GitHub/DSA1101 Slayers/Tutorial Solutions/Tut7-Rcode.R", echo=TRUE)
source("~/GitHub/DSA1101 Slayers/Tutorial Solutions/Tut9-Rcode.R", echo=TRUE)
source("~/GitHub/DSA1101 Slayers/Tutorial Solutions/Tut10-Rcode.R", echo=TRUE)
source("~/GitHub/DSA1101 Slayers/Tutorial Solutions/COMBINED tut1-6-Rcode.R", echo=TRUE)
